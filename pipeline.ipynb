{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ноутбук для экспериментов и измерения метрик\n",
    "\n",
    "Работает с окружением vtb или vtb_dgx_server\n",
    "\n",
    "Также можно использовать скрипт без визуализации (vis=False)\n",
    "\n",
    "```bash\n",
    "source activate vtb\n",
    "cd VTB_OCR/\n",
    "PYTHONPATH=. python scripts/evaluate.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 2.0.4 (you have 1.4.7). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nip\n",
    "from albumentations import NoOp, RandomRotate90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')\n",
    "torch.cuda.empty_cache()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт инструментов из библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konovalenko_f/vtb_project/VTB_OCR/lib/core/trainer.py:20: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n",
      "/home/konovalenko_f/vtb_project/VTB_OCR/lib/generation/tools/layer_morph.py:348: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def get_inverse_map(warp_map):\n",
      "/home/konovalenko_f/vtb_project/VTB_OCR/lib/generation/generators/warp_image_generator.py:14: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def get_displacement_field(shape, value=None):\n"
     ]
    }
   ],
   "source": [
    "from lib.data.ocr_dataset import CollectedDataset\n",
    "from lib.models.detection.YOLOX.yolox_predictor import YOLOXPredictor\n",
    "from lib.evaluation.general_evaluator import GeneralEvaluator\n",
    "from lib.models.recognition.rec_predictor import RecPredictor\n",
    "from lib.models.detection.seg_predictor import SegPredictor\n",
    "from lib.models.dewarping.rotation_predictor import RotPredictor\n",
    "from lib.models.dewarping.convnet import ConvNet\n",
    "from lib.utils import register_everything, load_model\n",
    "\n",
    "register_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пути к датасетам и моделям\n",
    "\n",
    "**Датасеты**\n",
    "\n",
    "Используется 3 датасета\n",
    "- collected_v1.3 (датасет сканов паспортов РФ)\n",
    "- docs_new (датасет сканов паспортов РФ и фото разных документов)\n",
    "- different_docs_2025 (датасет сканов и фото разных документов)\n",
    "\n",
    "**Модели**\n",
    "\n",
    "В текущей версии 1 тип детектора и 1 тип OCR модели (наиболее перспективные)\n",
    "- YOLOX\n",
    "- модель на базе tiny ViTSTR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_data_pth = '/data/shared/VTB_OCR/datasets/different_docs_2025'\n",
    "# passp_data_pth = '/data/shared/VTB_OCR/datasets/docs_new'\n",
    "# data_pth = '/data/shared/VTB_OCR/datasets/open_passports/collected_v1.3'\n",
    "\n",
    "yolo_b = '/home/belyaev_v/experiments/yolox_ddi+birth_0.67_0.75_lr_0.001_size_960_nt/model_last.pth'\n",
    "yolo_s = '/home/belyaev_v/experiments/yolox_ddi+snils_0.67_0.75_lr_0.001_size_960/model_last.pth'\n",
    "rec_pth = '/data/shared/VTB_OCR/experiments/ocr/vitstr/backbone_vit_tiny_4_8_cat_new_set_from_pre/model_850.pth'\n",
    "rec_pth_n = '/data/shared/VTB_OCR/experiments/ocr/sviptr/VIPTRv2T_ch_in_3_CTC_cat_new_set_noise/model_3000.pth'\n",
    "rec_pth_new = '/data/shared/VTB_OCR/experiments/ocr/sviptr/VIPTRv2T_ch_CTC_gray_mixed_docs/model_last.pth'\n",
    "rec_pth_new_cyr = '/data/shared/VTB_OCR/experiments/ocr/sviptr/VIPTRv2T_ch_CTC_gray_russian_docs/model_2500.pth'\n",
    "dew_pth = \"/data/shared/VTB_OCR/experiments/dewarping/convnet_rotation/rotation.pth\"\n",
    "\n",
    "# UNets\n",
    "unet_b_no_templates = \"/data/shared/VTB_OCR/experiments/detection/unet_ddi+birtonly_aug_nt_4_8_lr_0.001_size_1280/model_last.pth\"\n",
    "unet_s_no_templates = \"/data/shared/VTB_OCR/experiments/detection/unet_ddi+snilsonly_aug_4_8_lr_0.001_size_1280/model_last.pth\"\n",
    "\n",
    "vocab = nip.load('configs/recognition/datasets/alphabet.nip')\n",
    "vocab_ru = nip.load('configs/recognition/datasets/alphabet_ru.nip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициализация датасета с разметкой по словам\n",
    "\n",
    "- path - путь к папке датасета\n",
    "- gray - одноканальное изображение или нет\n",
    "- mode - для e2e пайплайна - end2end. В режиме recognition датасет обрезает боксы по GT разметке и отдает отдельные слова\n",
    "если нет OCR разметки и нужен предикт без расчета метрик - использовать detection\n",
    "- transform - для e2e пайплайна - None (на выходе из датасета изображение в формате np.array)\n",
    "- convert_to_rgb - True\n",
    "- skip_empty_text - True\n",
    "- skip_template_words - True (для формата данных ВТБ)\n",
    "- skip_vertical_text - True (для разметки где есть флаг вертикальности бокса)\n",
    "- box_expand - (-1, -1) - коэффициенты расширения GT боксов\n",
    "- output_shape - (960, 640) - размер изображения на выходе из датасета (H, W)\n",
    "- subset - поддатасет: для collected_v1.3 ('all') для docs_new - ('scans', 'photos')\n",
    "- split - сплит: для collected_v1.3 ('valid') для docs_new - не указывается\n",
    "- vocab - None - словарь\n",
    "- name - имя датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = CollectedDataset(path=td_data_pth,\n",
    "                      gray=False,\n",
    "                      mode='end2end',\n",
    "                      transform=None,\n",
    "                      convert_to_rgb=True,\n",
    "                      skip_empty_text=False,\n",
    "                      skip_template_words=False,\n",
    "                      skip_vertical_text=True,\n",
    "                      box_expand=(-1, -1),\n",
    "                      output_shape=(960, 640),\n",
    "                      subset='snils',\n",
    "                      split=\"valid\",\n",
    "                      vocab=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициализация деварпера\n",
    "\n",
    "В данном случае - корректор угла поворота для повернутых или перевернутых изображений\n",
    "ConvNet модель и обертка для нее\n",
    "\n",
    "- dew_path - путь к модели\n",
    "- name - имя модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/shared/CONDAENVS/vtb_dgx_server/lib/python3.8/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/data/shared/CONDAENVS/vtb_dgx_server/lib/python3.8/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "net = ConvNet()\n",
    "rot = load_model(path=dew_pth, model=net)\n",
    "dewarper = RotPredictor(model=rot,\n",
    "                        device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициализация детектора\n",
    "\n",
    "Unet модель и обертка для нее\n",
    "\n",
    "- det_path - путь к модели\n",
    "- gray - одноканальное изображение или нет - для Unet - True\n",
    "- name - имя модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo = load_model(yolo_b, device=DEVICE)\n",
    "# detector = YOLOXPredictor(yolo,\n",
    "#                          device=DEVICE,\n",
    "#                          gray=False,\n",
    "#                          img_shape=(960, 960),\n",
    "#                          name=yolo_b.split(\"/\")[-2],\n",
    "#                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = load_model(unet_s_no_templates, device=DEVICE)\n",
    "detector = SegPredictor(unet,\n",
    "                         device=DEVICE,\n",
    "                         gray=False,\n",
    "                         img_shape=(1280, 832),\n",
    "                         name=unet_s_no_templates.split(\"/\")[-2],\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициализация OCR\n",
    "\n",
    "ViT based модель и обертка для нее\n",
    "\n",
    "- rec_path - путь к модели\n",
    "- gray - одноканальное изображение или нет - для VitSTR - False\n",
    "- input_shape - размер бокса на входе в OCR модель\n",
    "- name - имя модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lib.models.recognition.sviptr.sviptr:No sequence_modeling module specified\n"
     ]
    }
   ],
   "source": [
    "ocr = load_model(rec_pth_new_cyr)\n",
    "recognizer = RecPredictor(model=ocr,\n",
    "                         gray=True,\n",
    "                         device=DEVICE,\n",
    "                         name=rec_pth_new_cyr.split(\"/\")[-2],\n",
    "                         input_shape=(32, 256),\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициализация Эвалюатора\n",
    "\n",
    "- dewarper - модель деварпинга\n",
    "- detector - модель детекции\n",
    "- recognizer - OCR - может быть None, в этом случае распознавание символов не производится, метрики не считаются\n",
    "- onestage_predictor - one stage модель\n",
    "- entity_matcher - модель мэтчинга сущностей\n",
    "- corrector - модель корректировки сущностей\n",
    "- test_dataset - датасет\n",
    "- skip_num - пропускаем ли номер паспорта (GT бокс, содержащий только цифры и пробелы) при расчете TD и OCR метрик\n",
    "- skip_serv - пропускаем ли сервисные поля при расчете TD и OCR метрик\n",
    "- skip_mrz - пропускаем ли MRZ при расчете TD и OCR метрик\n",
    "- correct_ocr - корректируем или нет предсказания OCR модели\n",
    "- save_crops - сохранение нарезанных боксов (если True - в корневой папке создается папка word_crops куда сохраняются нарезанные боксы и результаты распознавания в них.)\n",
    "- save_path - путь для сохранения результатов OCR в формате .csv\n",
    "- archive - путь для архивирования результатов эксперимента\n",
    "- comment - комментарий\n",
    "- timeout - задержка между изображениями если хочется подробнее рассмотреть. Если не 0 - то вывод ячейки не очищается\n",
    "- stop - на каком кадре останавливаемся\n",
    "- vis - отрисовка результатов TD (если мэтчинг не задан) или деварпинга и мэтчинга (если мэтчинг задан) в ноутбуке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример TD + OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "general = GeneralEvaluator(dewarper=None,\n",
    "                           detector=detector,\n",
    "                           recognizer=recognizer,\n",
    "                           onestage_predictor=None,\n",
    "                           entity_matcher=None,\n",
    "                           corrector=None,\n",
    "                           test_dataset=test_set,\n",
    "                           skip_num=False,\n",
    "                           skip_template_words=True,\n",
    "                           skip_mrz=False,\n",
    "                           save_crops=False,\n",
    "                           correct_ocr=True,\n",
    "                           device=DEVICE, \n",
    "                           save_path=None,\n",
    "                           archive=None,\n",
    "                           comment='snils',\n",
    "                           timeout=0,\n",
    "                           stop=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 36/36 [00:09<00:00,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 35 processed\n",
      "Batch processing time (dewarping) - 0.0 seconds\n",
      "Batch processing time (one stage) - 0.0 seconds\n",
      "Batch processing time (detection) - 0.0941 seconds\n",
      "Batch processing time (recognition) - 0.016 seconds\n",
      "Batch processing time (entity matching) - 0.0 seconds\n",
      "____________________\n",
      "\n",
      "____________________\n",
      "\n",
      "Mean metric IOU - 0.806\n",
      "____________________\n",
      "\n",
      "Mean metric AVERAGE_PRECISION@60-95 - 0.315\n",
      "____________________\n",
      "\n",
      "Mean metric AVERAGE_RECALL@60-95 - 0.684\n",
      "____________________\n",
      "\n",
      "Mean metric AVERAGE_FSCORE@60-95 - 0.612\n",
      "____________________\n",
      "\n",
      "Mean metric PRECISION@IOU0.6 - 0.714\n",
      "____________________\n",
      "\n",
      "Mean metric RECALL@IOU0.6 - 0.882\n",
      "____________________\n",
      "\n",
      "Mean metric FSCORE@IOU0.6 - 0.789\n",
      "____________________\n",
      "\n",
      "Mean metric WORD_ACCURACY - 0.882\n",
      "____________________\n",
      "\n",
      "Mean metric SIMILARITY - 0.882\n",
      "____________________\n",
      "\n",
      "Mean metric CHARACTER_ERROR - 8.16\n",
      "____________________\n",
      "\n",
      "Mean metric LEVENSHTEIN_DISTANCE - 0.118\n",
      "____________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION COMPLETED\n",
      "Result saved to results_None file\n",
      "Metrics saved to metrics_None file\n",
      "Experiment metrics saved to None file\n"
     ]
    }
   ],
   "source": [
    "result, metric = general.evaluate(vis=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '2025-02-19 13:38:16',\n",
       " 'dataset': 'different_docs_2025',\n",
       " 'comment': 'snils',\n",
       " 'detector': 'unet_ddi+snilsonly_aug_4_8_lr_0.001_size_1280',\n",
       " 'ocr_recognizer': 'VIPTRv2T_ch_CTC_gray_russian_docs',\n",
       " 'dewarper_time': 0.0,\n",
       " 'onestage_time': 0.0,\n",
       " 'detector_time': 0.0943,\n",
       " 'recognizer_time': 0.0272,\n",
       " 'matching_time': 0.0,\n",
       " 'device': device(type='cuda'),\n",
       " 'iou': 0.752,\n",
       " 'average_precision@60-95': 0.374,\n",
       " 'average_recall@60-95': 0.579,\n",
       " 'average_fscore@60-95': 0.542,\n",
       " 'precision@IoU0.6': 0.796,\n",
       " 'recall@IoU0.6': 0.888,\n",
       " 'fscore@IoU0.6': 0.83,\n",
       " 'word_accuracy': 0.844,\n",
       " 'similarity': 0.845,\n",
       " 'character_error': 12.487,\n",
       " 'levenshtein_distance': 0.112}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>pred</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ГОДА</td>\n",
       "      <td>ГОДА</td>\n",
       "      <td>0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004</td>\n",
       "      <td>2004</td>\n",
       "      <td>0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ЯНВАРЯ</td>\n",
       "      <td>ЯНВАРЯ</td>\n",
       "      <td>0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>МУЖСКОЙ</td>\n",
       "      <td>МУЖСКОЙ</td>\n",
       "      <td>0030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gt     pred filename\n",
       "0     ГОДА     ГОДА     0030\n",
       "0     2004     2004     0030\n",
       "0   ЯНВАРЯ   ЯНВАРЯ     0030\n",
       "0       19       19     0030\n",
       "0  МУЖСКОЙ  МУЖСКОЙ     0030"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.read_csv('/data/shared/VTB_OCR/experiments/history.csv', index_col=0).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vtb_dgx_server",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
